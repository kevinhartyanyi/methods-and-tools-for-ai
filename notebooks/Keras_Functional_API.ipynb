{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras - Functional API.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nf6E888AgP3l"
      },
      "source": [
        "# Keras Functional API\n",
        "This notebook shows how to use the  Functional API of Keras by implementing a 20 layer resnet. \n",
        "\n",
        "Up until this point we have only seen examples where layers were following each other sequentially. The input of the current layer was always the output of the previous layer. This setup was the standard until about 2014-15 when the InceptionNet and ResNet architectures appeared. Both have more complicated connections then simple sequential ones.\n",
        "\n",
        "Previous examples used the Sequential model API designed specifically for sequential models. The functional API let's you connect layers arbitrarily, in whatever way you want. It is very useful for more advanced architectures. Addtionally, it enables the network to have multiple inputs and outputs.\n",
        "\n",
        "## Functional API example\n",
        "First we will show how can the two layer network from the second lesson be written using Functional API. The network written in with the Sequential API looks like the following:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijfAYgXp8odW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e59a7790-191b-4a37-9aa3-2ddcca4dbeef"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "seq_model = Sequential()\n",
        "seq_model.add(Dense(64, input_shape=(16,)))\n",
        "seq_model.add(Dense(64))\n",
        "seq_model.add(Dense(10))\n",
        "\n",
        "seq_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 64)                1088      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 5,898\n",
            "Trainable params: 5,898\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UZhBZKN9av1"
      },
      "source": [
        "The same model with Functional API:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eu3NQJW27xGj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "444cd3a1-13ee-4a70-8d19-4d966a329f82"
      },
      "source": [
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# This returns a tensor\n",
        "input = Input(shape=(16,))\n",
        "\n",
        "# A layer instance is callable on a tensor, and returns a tensor\n",
        "# The parameters are the inputs, and the result of the call is the output tensor.\n",
        "output1 = Dense(64, activation='relu')(input)\n",
        "output2 = Dense(64, activation='relu')(output1)  # Here we connect the output of the first layer to the second layer\n",
        "predictions = Dense(10, activation='softmax')(output2)  # Here we connect the output of the second layer to the last layer\n",
        "\n",
        "# This creates a model that includes\n",
        "# the Input layer and three Dense layers\n",
        "func_model = Model(inputs=input, outputs=predictions)\n",
        "func_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 16)]              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 64)                1088      \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 5,898\n",
            "Trainable params: 5,898\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhhkJa1T7wOa"
      },
      "source": [
        "Basically, in the Functional API you have to declare how the layers are connected by passing the outputs of a layer as an input to another layer. Each layer is a Python callable and it expects as input a placeholder tensor and produces another tensor. The shape of the Input tensor has to be specified, from then on shapes are automatically calculated.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ep6rXoUSgP4a"
      },
      "source": [
        "## The ResNet architecture\n",
        "\n",
        "The next example contains the newer variant of ResNet trained on CIFAR10 dataset. The architecture can be viewed [here](http://vegesm.web.elte.hu/resnet-20-keras.png).\n",
        "\n",
        "\n",
        "### Setup\n",
        "First do some imports needed later:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CpPfeOggP4e"
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
        "from tensorflow.keras.layers import AveragePooling2D, Input, Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "import numpy as np\n",
        "import os\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmwN68sRgP4o"
      },
      "source": [
        "Next, load and normalize the data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "tOPG4DjjgP4p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "644eebdf-6502-4e6d-9da2-f32bba466190"
      },
      "source": [
        "\n",
        "# Load the CIFAR10 data.\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Input image dimensions.\n",
        "input_shape = x_train.shape[1:]\n",
        "\n",
        "# Normalize data.\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255\n",
        "\n",
        "# Normalize data by subtracting the mean, slightly improves the results\n",
        "x_train_mean = np.mean(x_train, axis=0)\n",
        "x_train -= x_train_mean\n",
        "x_test -= x_train_mean\n",
        "\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "print('y_train shape:', y_train.shape)\n",
        "\n",
        "# Convert class vectors to binary class matrices.\n",
        "y_train = keras.utils.to_categorical(y_train, 10)\n",
        "y_test = keras.utils.to_categorical(y_test, 10)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 4s 0us/step\n",
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n",
            "y_train shape: (50000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYCQDDHbgP5B"
      },
      "source": [
        "### Creating the nework\n",
        "First we define the `resnet_layer` function. This function creates a 2D Convolution-Batch Normalization-Activation stack of layers that will serve as a basic bulidng block. The return value `x` is a tensor that can be used as input to the next layer. \n",
        "\n",
        "The block looks like this:  \n",
        "<center><img src=\"https://drive.google.com/uc?id=14AOnj3igJGGpnmIfvhuE1U_GffI1LR2Q\" width=\"50%\" /></center>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gAz4x72EgP5F"
      },
      "source": [
        "def resnet_layer(inputs,\n",
        "                 num_filters=16,  # parameters for the convolution\n",
        "                 kernel_size=3,\n",
        "                 strides=1,\n",
        "                 activation='relu',  # name of the activation function\n",
        "                 batch_normalization=True,  # should we include a batchnorm layer\n",
        "                 conv_first=True):\n",
        "    \n",
        "    conv = Conv2D(num_filters,\n",
        "                  kernel_size=kernel_size,\n",
        "                  strides=strides,\n",
        "                  padding='same',\n",
        "                  kernel_initializer='he_normal',\n",
        "                  kernel_regularizer=l2(1e-4))\n",
        "\n",
        "    x = inputs\n",
        "\n",
        "    # Should the convolution come before the BatchNorm+ReLu or the other way?\n",
        "    if conv_first:\n",
        "        x = conv(x)\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "    else:\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "        x = conv(x)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldkXB1wlgP5n"
      },
      "source": [
        " One residual block contains a stack of (1 x 1)-(3 x 3)-(1 x 1) convolutions with BatchNormalization and ReLU layers. Here is a diagram of the block:\n",
        "<center><img src=\"https://drive.google.com/uc?id=11c7I0m8Xk_6TX9TT76K0QFJw0OvTnV7U\"  /></center>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-lh7gidrcEQ"
      },
      "source": [
        "def resnet_block(x, num_filters_in, num_filters_out, strides, activation, batch_normalization,\n",
        "                 conv_on_bottleneck):\n",
        "    y = resnet_layer(inputs=x, num_filters=num_filters_in, kernel_size=1,\n",
        "                      strides=strides, activation=activation, batch_normalization=batch_normalization,\n",
        "                      conv_first=False)\n",
        "    y = resnet_layer(inputs=y, num_filters=num_filters_in,\n",
        "                      kernel_size=3, conv_first=False)\n",
        "    y = resnet_layer(inputs=y,  num_filters=num_filters_out,\n",
        "                      kernel_size=1,  conv_first=False)\n",
        "    \n",
        "    # In each stage the first block decreases the size of the feature maps \n",
        "    # and increases the number of filters. We can only add tensors of the same dimensions,\n",
        "    # so in the skip-connection we have to resize the input.\n",
        "    # We do that by simply doing a 1x1 convolution\n",
        "    if conv_on_bottleneck:\n",
        "        x = resnet_layer(inputs=x,\n",
        "                          num_filters=num_filters_out,\n",
        "                          kernel_size=1,\n",
        "                          strides=strides,\n",
        "                          activation=None,\n",
        "                          batch_normalization=False)\n",
        "    x = keras.layers.add([x, y])\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8oaXjyxrbs9"
      },
      "source": [
        "The ResNet presented here have 3 stages, each stage having two residual blocks. At the beginning of each stage, the feature map size is halved (downsampled) by the end of the first residual block, while the number of filter maps is doubled. After that, within each stage, the resiudal blocks' input and output size does not change.\n",
        "\n",
        "Features maps sizes and number of filters after each stage:\n",
        "- conv1 (pre stage 0): 32x32,  16\n",
        "- stage 0: 32x32,  64\n",
        "- stage 1: 16x16, 128\n",
        "- stage 2:  8x8,  256"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3MWM_lygP5q"
      },
      "source": [
        "def resnet_v2(input_shape, num_res_blocks, num_classes=10):\n",
        "    \"\"\"\n",
        "    Creates a ResNetv2 model.\n",
        "    \n",
        "    Parameters:\n",
        "      input_shape: shape of input image tensor\n",
        "      num_res_blocks: number of residual blocks per stages\n",
        "      num_classes: number of output classes (CIFAR10 has 10)\n",
        "    Returns:\n",
        "      The Keras model.\n",
        "    \"\"\"\n",
        "        \n",
        "    # Start model definition.\n",
        "    num_filters = [16, 64, 128, 256]\n",
        "\n",
        "    inputs = Input(shape=input_shape)\n",
        "    \n",
        "    # ResNet first performs a Conv2D with BN-ReLU on input before splitting into 2 paths\n",
        "    x = resnet_layer(inputs=inputs,\n",
        "                     num_filters=num_filters[0],\n",
        "                     conv_first=True)\n",
        "\n",
        "    # Instantiate the stack of residual units\n",
        "    for stage in range(3):\n",
        "        for res_block in range(num_res_blocks):\n",
        "            activation = 'relu'\n",
        "            batch_normalization = True\n",
        "            if stage == 0 and res_block == 0:  # first layer and first stage\n",
        "                activation = None\n",
        "                batch_normalization = False\n",
        "\n",
        "            strides = 2 if stage>0 and res_block==0 else 1  # First layer, not first stage has a stride\n",
        "\n",
        "            x = resnet_block(x, num_filters[stage], num_filters[stage+1], strides, activation,\n",
        "                             batch_normalization, conv_on_bottleneck=(res_block == 0))\n",
        "\n",
        "\n",
        "    # Add classifier on top.\n",
        "    # v2 has BN-ReLU before Pooling\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = AveragePooling2D(pool_size=8)(x)\n",
        "    x = Flatten()(x)\n",
        "    outputs = Dense(num_classes,\n",
        "                    activation='softmax',\n",
        "                    kernel_initializer='he_normal')(x)\n",
        "\n",
        "    # Instantiate model.\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6POWG5mxgP5y"
      },
      "source": [
        "Next we train our neural network. The only new thing here is the callback property. Callbacks can be used in Keras to add extra steps to training that are performed on every epoch/iteration. Some examples:\n",
        "- `ModelCheckpoint`: saves the model on every epoch. Useful if you have a large model that takes a long time to train and you want to save the model every now and then in case the computer crashes.\n",
        "- `CsvLogger`: saves the train/validation accuracy and loss during training, useful for visualisations.\n",
        "- `ReduceLROnPlateau`: decreases the learning rate if the validation loss has stopped decreasing.\n",
        "\n",
        "We use the `ReduceLROnPlateau` callback that divides the learning rate by $\\sqrt{10}$ if the validation loss did not decrease for five epochs. It is an often useful startegy to decrease the learning rate over time.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYnMJwYdgP51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13ff6739-bd4f-48a2-9992-693cf07067d1"
      },
      "source": [
        "model = resnet_v2(input_shape=input_shape, num_res_blocks=2)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(lr=1e-3),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# This\n",
        "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
        "                               cooldown=0,\n",
        "                               patience=5,\n",
        "                               min_lr=0.5e-6)\n",
        "\n",
        "callbacks = [lr_reducer]\n",
        "\n",
        "# Run training\n",
        "# Training ResNet is slower than previous network, so it is trained only for 10 epochs.\n",
        "# To train it fully, you can run it for 100 or 200 epochs, if you have time!\n",
        "model.fit(x_train, y_train, batch_size=32,\n",
        "          epochs=10,\n",
        "          validation_data=(x_test, y_test),\n",
        "          shuffle=True,\n",
        "          callbacks=callbacks)\n",
        "\n",
        "\n",
        "# Score trained model.\n",
        "scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 24s 15ms/step - loss: 1.6801 - accuracy: 0.5222 - val_loss: 1.4749 - val_accuracy: 0.5819\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 24s 15ms/step - loss: 1.2365 - accuracy: 0.6585 - val_loss: 1.4130 - val_accuracy: 0.5790\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 24s 15ms/step - loss: 1.0540 - accuracy: 0.7200 - val_loss: 1.2277 - val_accuracy: 0.6551\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 24s 15ms/step - loss: 0.9445 - accuracy: 0.7559 - val_loss: 0.9917 - val_accuracy: 0.7338\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 24s 15ms/step - loss: 0.8682 - accuracy: 0.7848 - val_loss: 1.0765 - val_accuracy: 0.7273\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 24s 15ms/step - loss: 0.8138 - accuracy: 0.8038 - val_loss: 0.9937 - val_accuracy: 0.7386\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 24s 15ms/step - loss: 0.7700 - accuracy: 0.8177 - val_loss: 1.0146 - val_accuracy: 0.7423\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 24s 15ms/step - loss: 0.7327 - accuracy: 0.8324 - val_loss: 1.0315 - val_accuracy: 0.7495\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 24s 15ms/step - loss: 0.7003 - accuracy: 0.8457 - val_loss: 0.9000 - val_accuracy: 0.7796\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 24s 15ms/step - loss: 0.6799 - accuracy: 0.8538 - val_loss: 1.1990 - val_accuracy: 0.7413\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 1.1990 - accuracy: 0.7413\n",
            "Test loss: 1.1989514827728271\n",
            "Test accuracy: 0.7412999868392944\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4s5efjAJ81N"
      },
      "source": [
        "We have achieved 74% accuracy on CIFAR-10. With training the network much longer (200 epochs), one can achieve 91-92% accuracy."
      ]
    }
  ]
}