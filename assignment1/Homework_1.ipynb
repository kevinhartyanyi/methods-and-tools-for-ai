{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Homework 1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBKg7ZzaopQp"
      },
      "source": [
        "# Methods and Tools for AI - Homework 1\n",
        "\n",
        "Fill in the solutions in this notebook. For submission, save the notebook as an ipynb file (File -> Download .ipynb) then upload it to Canvas. Make sure the entire notebook is runnable after a reset!\n",
        "\n",
        "Please enter your name and Neptun code below for easier organisation:  \n",
        "**Name:**  \n",
        "**Neptun code:**\n",
        "\n",
        "Initial imports:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQi0Xv3f6BhN"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4iB7mtW17hv"
      },
      "source": [
        "## Numpy problems\n",
        "Solve these problems using numpy. Make sure  the solutions are vectorized, that is they don't use any Python loops, not even in the background (e.g. no for loops, `map` builtin function, etc.) A couple of tests are provided for each problem. Note that these tests are just examples for illustrating the task and are not exhaustive! Passing the tests doesn't necessarily mean the solution is correct.\n",
        "\n",
        "**1. [1 point]** Write the `cylinder_volume` function that takes an array of shape Nx2, where the first column is the radius, the second is the length of the cylinder. The function calculates the volume of the cylinder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8swkLKWBVzM"
      },
      "source": [
        "def cylinder_volume(a):\n",
        "  pass\n",
        "\n",
        "assert np.abs(cylinder_volume (np.array([[1,1]])) - np.array(3.14159265))<1e-5\n",
        "assert np.all(np.abs(cylinder_volume (np.array([[0,1], [2,2]])) - np.array([0, 25.132741]))<1e-5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngfKwdjdDWJi"
      },
      "source": [
        "**2. [2 points]** Create the `moving_sum` function that calculates the moving sum on an array. Specifically, it takes two parameters: `a` and `w` where `w` is the window size. For a one dimensional array the return array must be:\n",
        "\n",
        "`r[i] = a[i-w+1]+a[i-w+2]+...+a[i]`\n",
        "\n",
        "Note the length of the output `r` is `w-1` elements shorter. If `a` has multiple dimensions, calculate the moving sum over the last axis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caQwL7xjDVzL"
      },
      "source": [
        "def moving_sum(a, w):\n",
        "  pass\n",
        "\n",
        "assert np.all(moving_sum(np.array([1, 2, 3, 4, 5]), 2) == [3., 5., 7., 9.])\n",
        "assert np.all(moving_sum(np.array([[1, 2, 3, 4, 5], [24, -5, 3, 4, 8]]), 3) == [[ 6.,  9., 12], [22.,  2., 15.]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9e4Ur1FhM42g"
      },
      "source": [
        "**3. [2 points]**  We have a video, recorded in 25 FPS. We also have a list of timestamps when a certain event occured. Your task is to return the index of frames, where at least 3 events happened. The input timestamps are in miliseconds."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FV7pKIcuM5GQ"
      },
      "source": [
        "def at_least_3_events(timestamps):\n",
        "  pass\n",
        "\n",
        "assert np.all(at_least_3_events(np.array([10, 20]))==[])\n",
        "assert np.all(at_least_3_events(np.array([10, 20, 30, 40, 42, 81, 119, 90]))==[0, 2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgPsq-KzreZy"
      },
      "source": [
        "## Linear regression\n",
        "\n",
        "In this task, you'll have to use linear regression with custom feature functions to predict data. \n",
        "\n",
        "First download the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHmyrMe117Js"
      },
      "source": [
        "!wget http://vegesm.web.elte.hu/matai/train.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ac-ss0E92zZ1"
      },
      "source": [
        "**4. [2 points]** First fit a simple linear regression on the data, using bias parameters as well. The target variable is in the `y` column. What is the loss on the dataset? Plot the results!\n",
        "\n",
        "**5. [4 points]** Now implement polynomial features in the linear regeression model. Try polynomials up until of degree 4. What is their loss? Which one looks the best?\n",
        "\n",
        "**6. a) [2 points]** We have performed some more data collection, the resulting data is available here:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5oFga9N30ZP"
      },
      "source": [
        "!wget http://vegesm.web.elte.hu/matai/new_data.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1e8kOOu4HsS"
      },
      "source": [
        "Evaluate all the previously trained models (linear and polynomials of different degrees) on the new dataset. What is the error here? Why is it better/worse than the errors on the first batch of data?\n",
        "\n",
        "**6. b) [3 points]** By looking at the data, come up with a good feature function to estimate the target variable! Use only the first batch for training the regression parameters. Calculate the error on the new batch, it should be the smallest error among all the models trained so far."
      ]
    }
  ]
}