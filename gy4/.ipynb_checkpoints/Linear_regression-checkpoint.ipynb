{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2pKobZd0KxwP"
   },
   "source": [
    "\n",
    "**Created by:**\n",
    "\n",
    "__[Viktor Varga](https://github.com/vvarga90)__, __Gulyás János Adrián__  \n",
    "**Edited by Márton Véges**\n",
    "\n",
    "<br>\n",
    "\n",
    "<img src=\"https://docs.google.com/uc?export=download&id=1WzgXsCoz8O-NeBlJTbuLPC1iIFDmgYt1\" style=\"display:inline-block\">\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UPNGQgO6aXtZ"
   },
   "source": [
    "# Linear regression using gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EaVq4W9qOIIv"
   },
   "source": [
    "Source of the databases at: http://www.dcc.fc.up.pt/~ltorgo/Regression/DataSets.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9xF9psXQKgN7"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "eugRKr5_Kf7c"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import urllib.request\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UxnhbGQ-Jzxx"
   },
   "source": [
    "## Getting the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b8DWij2kFZRu"
   },
   "source": [
    "Loading in the data (\"Wine Quality Data Set\" from the UCI ML repository).\n",
    "\n",
    "**Exercise:** Let's rate the quality of wines on a scale from 1 to 10 based on the wine's chemical composition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Iuxqk43jFPCG"
   },
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/vvarga90/dlmatek_public_files/master/winequality-red.csv'\n",
    "\n",
    "ftpstream = urllib.request.urlopen(url)\n",
    "content_reg = ftpstream.read().decode('utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M_XRgr1mJFhs"
   },
   "source": [
    "Processing data: from text file to numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "id": "dPMWRt5qHfDy",
    "outputId": "2735087f-171e-4e21-fccc-1a20d3c2c59c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data attributes:\n",
      "['\"fixed acidity\"', '\"volatile acidity\"', '\"citric acid\"', '\"residual sugar\"', '\"chlorides\"', '\"free sulfur dioxide\"', '\"total sulfur dioxide\"', '\"density\"', '\"pH\"', '\"sulphates\"', '\"alcohol\"', '\"quality\"']\n",
      "(1000, 11)\n",
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "lines = content_reg.split('\\n')\n",
    "words = [line.split(';') for line in lines]\n",
    "attr_names = words[0]\n",
    "data = words[1:1001]\n",
    "data = [[float(item) for item in rec] for rec in data]\n",
    "data = np.array(data, dtype=np.float32)\n",
    "\n",
    "features = data[:,:-1]\n",
    "labels = data[:,-1]\n",
    "\n",
    "print(\"Data attributes:\")\n",
    "print(attr_names)\n",
    "print(features.shape)\n",
    "print(labels.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 129
    },
    "id": "MAAMvhNVZHsR",
    "outputId": "0048e4a5-f19c-499c-b47b-24ced27a9545"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.6     0.12    0.      1.2     0.012   1.      6.      0.99064 2.74\n",
      " 0.33    8.4     3.     ]\n",
      "[ 15.9      1.33     1.      15.5      0.611   68.     165.       1.0032\n",
      "   3.9      2.      14.9      8.    ]\n",
      "[ 8.728898    0.52829     0.29458055  2.5794      0.09037506 15.171\n",
      " 48.328       0.9973502   3.2990983   0.66852003 10.240709    5.594     ]\n"
     ]
    }
   ],
   "source": [
    "# what is the range? what is the min/max? what is the mean?\n",
    "print(np.amin(data,axis=0))\n",
    "print(np.amax(data,axis=0))\n",
    "print(np.mean(data,axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "MrFEaDTRb8HE",
    "outputId": "0c181830-b045-4886-b72a-59e22fc13dce"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Its also useful to plot histograms of the features\n",
    "plt.figure()\n",
    "plt.hist(data[:, 0], bins=50);  # Jupyter tip: add a ';' at the end, to suppress the text output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_H7B_EggKKrE"
   },
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "munYcZbIksAL"
   },
   "source": [
    "As a reminder we would like to find the optimal parameter $\\theta$ for the function\n",
    "$$f_{\\theta}(x)=\\theta_0+\\theta x$$\n",
    "such that it minimizes the squared error:\n",
    "$$L(\\mathcal{D},\\theta)=\\frac{1}{N}\\sum_{n=1}^N(y_n-f_{\\theta}(x_n))^2.$$\n",
    "\n",
    "On the lecture we learned about the normal equation to solve this:\n",
    "$$\\theta=(X^TX)^{-1}X^Ty,$$\n",
    "where each row of $X$ contains the features of one datapoint from the dataset. Turns out this is a really bad approach to solve this problem due to numerical instabilities (see the exercise at the end of the notebook) and also very slow if you have many features. Instead, we are going to use gradient descent, to solve the problem. First note that (ignoring $\\theta_0$):\n",
    "$$L(\\mathcal{D},\\theta)=\\frac{1}{N}\\sum_{n=1}^N(y_n-f_{\\theta}(x_n))^2=\\frac{1}{N}\\sum_{n=1}^N(y_n-\\theta x_n)^2.$$\n",
    "This is a quadratic function in $\\theta$, we can plot it:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KeTUVn2eWoHM"
   },
   "source": [
    "![alt](https://drive.google.com/uc?export=download&id=1kAr_3NqddrbZua1Z5EOgzPnJlQphpKX6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6DDTpewTWDkJ"
   },
   "source": [
    "The algorithm of gradient descent:\n",
    "1. Initialize $\\theta^{(0)}$ to zero (or set randomly)\n",
    "2. Update $\\theta$:  \n",
    "$\\theta^{(t)}=\\theta^{(t-1)}−\\alpha\\nabla_{\\theta} L(\\mathcal D, \\theta)$\n",
    "3. Iterate until it converges, or for a certain number of iterations.\n",
    "\n",
    "In our case $\\nabla_{\\theta} L(\\mathcal D, \\theta)=\\frac{1}{N}\\sum_{n=1}^N-2x_n(y_n-\\theta x_n)=-\\frac{2}{N}X^T(y-X\\theta)$. \n",
    "\n",
    "See below the implementation of the linear regression class. `fit_intercept` is `True` if we want to use the $\\theta_0$ constant parameter. The trick to add back $\\theta_0$ to our formula:\n",
    "$$x_n'=(1,x_n),\\  \\theta'=\\begin{pmatrix}\\theta_0 \\\\ \\theta \\end{pmatrix}$$\n",
    "\n",
    "$$L(\\mathcal D, \\theta)=\\frac{1}{N}\\sum_{n=1}^N(y_n-\\theta_0-\\theta x_n)^2=\\frac{1}{N}\\sum_{n=1}^N(y_n-\\theta' x_n')^2$$\n",
    "In vectorized form:\n",
    "$$X'=\\left[\\begin{array}{c|c}\n",
    "\\begin{matrix}1 \\\\ \\vdots \\\\ 1 \\end{matrix} & X \n",
    "\\end{array}\n",
    "\\right]$$\n",
    "This trick lets us handle $\\theta_0$ as part of $\\theta$, simplifying our code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "UIe5x8koksAj"
   },
   "outputs": [],
   "source": [
    "class LinearRegression:\n",
    "    def __init__(self, lr=0.01, num_iter=10000, fit_intercept=True):\n",
    "        self.lr = lr\n",
    "        self.num_iter = num_iter\n",
    "        self.fit_intercept = fit_intercept\n",
    "        self.train_theta = []\n",
    "        #self.eps = 0.00000001\n",
    "    \n",
    "    def __add_intercept(self, X):\n",
    "        # add a column of 1s\n",
    "        intercept = np.ones((X.shape[0], 1))\n",
    "        return np.concatenate((intercept, X), axis=1)\n",
    "    \n",
    "    def __loss(self, h, y):\n",
    "        return np.mean(np.square(h - y))\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        if self.fit_intercept:\n",
    "            X = self.__add_intercept(X)\n",
    "        \n",
    "        # weights initialization\n",
    "        self.theta = np.zeros(X.shape[1])\n",
    "        \n",
    "        loss_vals = []\n",
    "        self.train_theta = []\n",
    "        for i in range(self.num_iter):\n",
    "            h = np.dot(X, self.theta)\n",
    "            gradient = 2*np.dot(X.T, h - y) / y.size\n",
    "            self.theta -= self.lr * gradient\n",
    "            print(self.theta)\n",
    "            \n",
    "            self.train_theta.append(self.theta)\n",
    "            \n",
    "            h = np.dot(X, self.theta)\n",
    "            loss = self.__loss(h, y)\n",
    "            loss_vals.append(loss)\n",
    "        \n",
    "        return loss_vals\n",
    "    \n",
    "    def predict(self, X):\n",
    "        if self.fit_intercept:\n",
    "            X = self.__add_intercept(X)\n",
    "    \n",
    "        return np.dot(X, self.theta)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NYO1QIceKdEe"
   },
   "source": [
    "## Preprocessing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1YocW5c_Ku4W"
   },
   "source": [
    "Selecting X, Y, separating the data into a train and a test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 92
    },
    "id": "6ATDtyb6K-dK",
    "outputId": "8a9d9bbf-4435-4533-c0cb-796a6315f15f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 11)\n",
      "(500,)\n",
      "(500, 11)\n",
      "(500,)\n"
     ]
    }
   ],
   "source": [
    "X_train = features[:500]\n",
    "y_train = labels[:500]\n",
    "X_test = features[500:]\n",
    "y_test = labels[500:]\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y_tZc4QSbeev"
   },
   "source": [
    "Feature scaling methods: one for calculating the average and the deviation of each feature, which will be used for normalizing the input, and another one that normalizes an input based on the already calculated average and deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "L2pQ3lkUbhcv"
   },
   "outputs": [],
   "source": [
    "def std_normalization(data):\n",
    "    # params: data: ndarray(n_samples, n_features)\n",
    "    data = np.asarray(data, dtype=np.float64)\n",
    "    eps = 0.0000001\n",
    "    x_mean = np.mean(data, axis=0)\n",
    "    x_std = np.std(data, axis=0)\n",
    "    x_norm = (data-x_mean) / (x_std + eps)\n",
    "    \n",
    "    return x_norm, x_mean, x_std\n",
    "  \n",
    "def std_normalize_with_given_meanstd(data, x_mean, x_std):\n",
    "    eps = 0.0000001\n",
    "    x_norm = (data-x_mean) / (x_std + eps)\n",
    "    return x_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Hg6suT-0lwb7"
   },
   "outputs": [],
   "source": [
    "X_train_n, x_mean, x_std = std_normalization(X_train)\n",
    "X_test_n = std_normalize_with_given_meanstd(X_test, x_mean, x_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "In-I8wdxlwca"
   },
   "source": [
    "## Training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 302
    },
    "id": "9bZ5AIn0lwci",
    "outputId": "b2c15c1f-ee2a-40c3-f48c-e2a461989023"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXEAAAD4CAYAAAAaT9YAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAATfklEQVR4nO3df4xlZX3H8ff33jv7g13KLjLgCsQFNRqMdYERNRqDWlukpmprWvnDkJZkTdVEU5sGNW01aRq19Wdq1VWINPEXrRIooVVKsGo04KwssIB0F8TAurDjj2X5uezsfvvHfWbm3pk7O7PzY+88M+9XcnPPfe65c75nuPPh2ec855zITCRJdWr0uwBJ0twZ4pJUMUNckipmiEtSxQxxSapY63hu7JRTTsnNmzcfz01KUvW2b9/+q8wc7PXecQ3xzZs3Mzw8fDw3KUnVi4hfTPeewymSVDFDXJIqZohLUsUMcUmqmCEuSRUzxCWpYoa4JFWsihC/6Z5H+Nfv7e53GZK05FQR4t+7d4Qv/+Dn/S5DkpacKkK8EXDEm1dI0hRVhHhEcPiIIS5Jk1UR4s1GYEdckqaqIsQbgT1xSeqhjhBvhGPiktRDHSEeDqdIUi+VhDgcNsUlaYoZQzwi1kTErRFxe0TcFREfKe1nRcQtEbE7Ir4ZEasWq8hmOJwiSb3Mpid+EHhdZr4U2AJcFBGvAD4GfCoznw/8FrhssYqMMpySBrkkdZkxxLPt8fJyoDwSeB3wH6X9KuAti1Ih7SmGAE5QkaRusxoTj4hmROwA9gE3AvcB+zNztKzyEHD6NJ/dGhHDETE8MjIytyLbGe6QiiRNMqsQz8zDmbkFOAO4AHjRbDeQmdsycygzhwYHe96seUYR7RR3rrgkdTum2SmZuR+4GXglsCEiWuWtM4A9C1zbuLHhFDviktRtNrNTBiNiQ1leC7wBuId2mL+trHYpcO2iFelwiiT11Jp5FTYBV0VEk3boX52Z10fE3cA3IuIfgNuAKxaryMbYcIohLkldZgzxzLwDOLdH+/20x8cX3ViI55HjsTVJqkc1Z2yCPXFJmqyKEJ+YJ26IS1KnKkJ8bIqhIS5J3aoI8bEx8SOOiUtSlypCvFmqtCcuSd2qCHHP2JSk3qoI8WZ4xqYk9VJFiDccTpGknuoIcc/YlKSeqgpxbwohSd2qCnGPa0pSt0pCvP3s7BRJ6lZHiHvavST1VEeIe8amJPVURYh7xqYk9VZFiHsBLEnqrYoQbxjiktRTFSHedIqhJPVURYg7xVCSeqsjxJ1iKEk91RHiXsVQknqqJMTbzw6nSFK3OkLc4RRJ6mnGEI+IMyPi5oi4OyLuioj3lvYPR8SeiNhRHhcvWpEOp0hST61ZrDMKvD8zfxoRJwLbI+LG8t6nMvOfF6+8NodTJKm3GUM8M/cCe8vyYxFxD3D6YhfWyZN9JKm3YxoTj4jNwLnALaXpPRFxR0RcGREbp/nM1ogYjojhkZGRuRVpiEtST7MO8YhYD3wLeF9mHgA+DzwP2EK7p/6JXp/LzG2ZOZSZQ4ODg3MqstnwjE1J6mVWIR4RA7QD/KuZ+W2AzHwkMw9n5hHgS8AFi1ZkGRO3Jy5J3WYzOyWAK4B7MvOTHe2bOlZ7K7Bz4csb3xbggU1Jmmw2s1NeBbwDuDMidpS2DwKXRMQWIIEHgHcuSoVMDKfYEZekbrOZnfJDIHq8dcPCl9ObUwwlqbc6zth0dook9VRHiDucIkk91RHiY8MpprgkdakixJsOp0hST1WEeHh7NknqqYoQHz/ZxxSXpC5VhHjT64lLUk9VhLhnbEpSb1WEuGdsSlJvVYS4F8CSpN4qCfEynGKIS1KXqkLcDJekbpWEePvZA5uS1K2KEHeKoST1VkWIe8amJPVWRYhDe0jFMzYlqVs1Id5shMMpkjRJNSEeEU4xlKRJqgnxViMcTpGkSaoJ8WYjGDXEJalLVSHuPHFJ6lZNiLcMcUmaYsYQj4gzI+LmiLg7Iu6KiPeW9pMj4saI2FWeNy5qoWGIS9Jks+mJjwLvz8xzgFcA746Ic4DLgZsy8wXATeX1orEnLklTzRjimbk3M39alh8D7gFOB94MXFVWuwp4y2IVCdBsGuKSNNkxjYlHxGbgXOAW4LTM3Fveehg4bZrPbI2I4YgYHhkZmXOhzXB2iiRNNusQj4j1wLeA92Xmgc73MjOBngmbmdsycygzhwYHB+dcaLPhyT6SNNmsQjwiBmgH+Fcz89ul+ZGI2FTe3wTsW5wS25qN4PBhQ1ySOs1mdkoAVwD3ZOYnO966Dri0LF8KXLvw5U1oNhr2xCVpktYs1nkV8A7gzojYUdo+CHwUuDoiLgN+Afzp4pTY5uwUSZpqxhDPzB8CMc3br1/YcqbX8LR7SZqiqjM2vQCWJHWrJsTbUwyP9LsMSVpS6gnxRmCGS1K3akK81bQnLkmTVRPiXgBLkqaqJsRbnrEpSVNUE+KNRjDqGZuS1KWaEG95t3tJmqKaEPcem5I0VVUh7oFNSepmiEtSxeoJcacYStIU1YR4y9uzSdIU1YS4J/tI0lTVhHjL2SmSNEU1Id5sNLwUrSRNUlGIY09ckiapKMS9x6YkTVZRiOOBTUmapKIQb3D4SJL2xiVpXDUh3mq079VsZ1ySJlQT4s0S4t7dR5ImVBfiZrgkTZgxxCPiyojYFxE7O9o+HBF7ImJHeVy8uGW2r50C9sQlqdNseuJfAS7q0f6pzNxSHjcsbFlTjfXEnaEiSRNmDPHM/D7wm+NQy1G1moa4JE02nzHx90TEHWW4ZeN0K0XE1ogYjojhkZGROW+sEYa4JE021xD/PPA8YAuwF/jEdCtm5rbMHMrMocHBwTlubmKKoWdtStKEOYV4Zj6SmYcz8wjwJeCChS1rqsbYFEPveC9J4+YU4hGxqePlW4Gd0627UFoe2JSkKVozrRARXwcuBE6JiIeAvwcujIgtQAIPAO9cxBqBzpN9DHFJGjNjiGfmJT2ar1iEWo5qoNn+R4PzxCVpQjVnbI6HuGPikjSumhAfmyf+zGF74pI0ppoQH2jYE5ekyeoJ8dITP2RPXJLGVRPirTImbohL0oRqQnyVBzYlaYpqQrzlcIokTVFNiI+PiXuyjySNqyjEy5j4qD1xSRpTTYi3PGNTkqaoJsQnphg6nCJJY+oJ8YZTDCVpsnpCvOUUQ0marJoQH7ueuNdOkaQJ1YS4VzGUpKmqCfFmI2iEY+KS1KmaEIf2NMNDTjGUpHFVhfiqZsPhFEnqUFWIt5rhcIokdagrxBsNT/aRpA5Vhfgqe+KS1KWqEG81G4wa4pI0bsYQj4grI2JfROzsaDs5Im6MiF3leePiltk20AwvRStJHWbTE/8KcNGktsuBmzLzBcBN5fWiG2g2vBStJHWYMcQz8/vAbyY1vxm4qixfBbxlgevqaaDZYNSeuCSNm+uY+GmZubcsPwycNt2KEbE1IoYjYnhkZGSOm2tziqEkdZv3gc3MTGDa7nFmbsvMocwcGhwcnNe2BhoNQ1ySOsw1xB+JiE0A5XnfwpU0vYFWOE9ckjrMNcSvAy4ty5cC1y5MOUe3qtngGQ9sStK42Uwx/DrwY+CFEfFQRFwGfBR4Q0TsAn6vvF50awaaHBw9fDw2JUlVaM20QmZeMs1br1/gWma0utXgoD1xSRpX1Rmbq1tNDh4yxCVpTF0hPtDgaYdTJGlcXSHeatgTl6QOlYV4+8Bme2q6JKmyEG9wJPHUe0kqqgrxNQNNAGeoSFJRVYivHmiXe/CQBzclCWoL8VYJcXvikgRUF+Lt4ZSn7YlLElBdiNsTl6ROdYX4gCEuSZ2qCvE1ZTjFA5uS1FZViNsTl6RudYV4y3niktSpshBvl+vsFElqqyzE7YlLUqeqQnxNGRN/yp64JAGVhfgJq9s3InrqmdE+VyJJS0NdIV4ugPX4QXvikgSVhXijEZywqsmTB+2JSxJUFuIAJ6xq8cQz9sQlCSoM8fWrmzxhT1ySgApD/IRVLZ70wKYkAdCaz4cj4gHgMeAwMJqZQwtR1NGsW93kCQ9sShIwzxAvXpuZv1qAnzMr61a3+O0TzxyvzUnSklbdcMq6VS0ed0xckoD5h3gC342I7RGxtdcKEbE1IoYjYnhkZGSem2sPpzzp7BRJAuYf4q/OzPOANwLvjojXTF4hM7dl5lBmDg0ODs5zc2WKoT1xSQLmGeKZuac87wOuAS5YiKKOZt3qJk88c5jMXOxNSdKSN+cQj4h1EXHi2DLw+8DOhSpsOutXD3D4SHoRLElifrNTTgOuiYixn/O1zPzvBanqKDacMADA/icPccKqhZhcI0n1mnMKZub9wEsXsJZZ2dgR4s/ZsPZ4b16SlpTqphietHYVAPufcq64JFUX4hvXTfTEJWmlqy7EN4z1xA1xSaowxMuY+G+fdDhFkqoL8TUDTdYMNHj0KXviklRdiEN7SMWLYElSpSF+6u+sZt9jB/tdhiT1XZUh/uzfWcPDjz7d7zIkqe/qDPGT1vDwAUNckqoN8UefOuRt2iSteFWG+KaT1gA4pCJpxas0xNvXTPnlfkNc0spWZYifPbgOgPtGHu9zJZLUX1WG+OD61Zy0doBd+x7rdymS1FdVhnhE8PxT17PrEXvikla2KkMc4IXPPpG79x7g8BFv0yZp5ao2xF+2eSOPPT3Kzx4+0O9SJKlvqg3xl5/1LAB+fN+v+1yJJPVPtSH+nA1redGzT+Q/79jb71IkqW+qDXGAt51/Brc/uJ8dD+7vdymS1BdVh/ifvexMTlm/mg9dc6en4EtakaoO8RPXDPCxP3kJ9+w9wFs/9yOu3bGHhx99miPOWJG0QkTm3AMvIi4CPgM0gS9n5kePtv7Q0FAODw/PeXvT+d69+/jba3fy4G+eAqARcNLaAVa1GjQjaDSCViNoREDMfTvz+CgR8/n0/LYtqf/+8Y9fwss2nzynz0bE9swc6vVea64FRUQT+BzwBuAh4CcRcV1m3j3XnzlXF77wVP73r1/LbQ/u565fPsq+AwfZ/9QzHBpNRo8kRzI5XJ7nal59+3n+wyDn+wMk9d3ageai/Nw5hzhwAbA7M+8HiIhvAG8GjnuIAzQawfnP3cj5z93Yj81LUl/MZ0z8dODBjtcPlbYuEbE1IoYjYnhkZGQem5MkTbboBzYzc1tmDmXm0ODg4GJvTpJWlPmE+B7gzI7XZ5Q2SdJxMp8Q/wnwgog4KyJWAW8HrluYsiRJszHnA5uZORoR7wG+Q3uK4ZWZedeCVSZJmtF8ZqeQmTcANyxQLZKkY1T1GZuStNIZ4pJUsXmddn/MG4sYAX4xx4+fAvxqAcupgfu8MrjPK8N89vm5mdlzjvZxDfH5iIjh6a4dsFy5zyuD+7wyLNY+O5wiSRUzxCWpYjWF+LZ+F9AH7vPK4D6vDIuyz9WMiUuSpqqpJy5JmsQQl6SKVRHiEXFRRNwbEbsj4vJ+13MsIuLKiNgXETs72k6OiBsjYld53ljaIyI+W/bzjog4r+Mzl5b1d0XEpR3t50fEneUzn4353gduAUTEmRFxc0TcHRF3RcR7S/uy3e+IWBMRt0bE7WWfP1Laz4qIW0qd3ywXiyMiVpfXu8v7mzt+1gdK+70R8Qcd7Uvu7yAimhFxW0RcX14v6/0FiIgHyndvR0QMl7b+fbczc0k/aF9c6z7gbGAVcDtwTr/rOob6XwOcB+zsaPs4cHlZvhz4WFm+GPgv2rfUfAVwS2k/Gbi/PG8syxvLe7eWdaN89o1LYJ83AeeV5ROB/wPOWc77XepYX5YHgFtKfVcDby/tXwD+siy/C/hCWX478M2yfE75jq8Gzirf/eZS/TsA/gr4GnB9eb2s97fU/ABwyqS2vn23+/4LmcUv7JXAdzpefwD4QL/rOsZ92Ex3iN8LbCrLm4B7y/IXgUsmrwdcAnyxo/2LpW0T8LOO9q71lsoDuJb2vVhXxH4DJwA/BV5O+wy9Vmkf/y7TvvrnK8tyq6wXk7/fY+stxb8D2vcQuAl4HXB9qX/Z7m9HLQ8wNcT79t2uYThlVreBq8xpmbm3LD8MnFaWp9vXo7U/1KN9ySj/bD6Xds90We93GVrYAewDbqTdk9yfmaNllc46x/etvP8o8CyO/XfRT58G/gY4Ul4/i+W9v2MS+G5EbI+IraWtb9/teV2KVvOXmRkRy3KeZ0SsB74FvC8zD3QO7S3H/c7Mw8CWiNgAXAO8qM8lLZqIeBOwLzO3R8SF/a7nOHt1Zu6JiFOBGyPiZ51vHu/vdg098eV4G7hHImITQHneV9qn29ejtZ/Ro73vImKAdoB/NTO/XZqX/X4DZOZ+4GbaQwIbImKss9RZ5/i+lfdPAn7Nsf8u+uVVwB9FxAPAN2gPqXyG5bu/4zJzT3neR/t/1hfQz+92v8eXZjH+1KI96H8WEwc4Xtzvuo5xHzbTPSb+T3QfBPl4Wf5Dug+C3FraTwZ+TvsAyMayfHJ5b/JBkIuXwP4G8G/Apye1L9v9BgaBDWV5LfAD4E3Av9N9oO9dZfnddB/ou7osv5juA3330z7It2T/DoALmTiwuaz3F1gHnNix/CPgon5+t/v+BZjlL+5i2jMc7gM+1O96jrH2rwN7gUO0x7cuoz0WeBOwC/ifjv94AXyu7OedwFDHz/kLYHd5/HlH+xCws3zmXyhn4fZ5n19Ne9zwDmBHeVy8nPcb+F3gtrLPO4G/K+1nlz/K3SXgVpf2NeX17vL+2R0/60Nlv+6lY2bCUv07oDvEl/X+lv27vTzuGqurn99tT7uXpIrVMCYuSZqGIS5JFTPEJalihrgkVcwQl6SKGeKSVDFDXJIq9v+dY06NX2PdfAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mean absolute error: 0.5001771395641166\n",
      "Test mean absolute error: 0.5162361807381445\n"
     ]
    }
   ],
   "source": [
    "# if features are not scaled to same magnitude higher learning rate causes big fluctuations\n",
    "# model = LinearRegression(lr=0.00001, num_iter=50000)   \n",
    "\n",
    "model = LinearRegression(lr=0.001, num_iter=50000)\n",
    "\n",
    "loss = model.fit(X_train_n, y_train)\n",
    "\n",
    "plt.plot(loss)\n",
    "plt.show();\n",
    "\n",
    "preds_train = model.predict(X_train_n)\n",
    "print(\"Training mean absolute error: \" + str(np.abs(preds_train - y_train).mean()))\n",
    "preds_test = model.predict(X_test_n)\n",
    "print(\"Test mean absolute error: \" + str(np.abs(preds_test - y_test).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "theta_means = [x.mean() for x in model.train_theta]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7efc2cec8880>]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(theta_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.74998298, 0.72978515, 0.72978515, 0.54252213, 0.51321053,\n",
       "       0.51391834, 0.55576404, 0.48786905, 0.36983303, 0.54825347,\n",
       "       0.77988776, 0.36983303, 0.28360459, 0.78675706, 0.78675706,\n",
       "       0.0747017 , 0.46569878, 0.56245544, 0.67373534, 0.01320689,\n",
       "       0.20745125, 0.34775734, 0.0408415 , 0.14861931, 0.61382622,\n",
       "       0.67373534, 0.18331795, 0.80127641, 0.42834654, 0.19548684,\n",
       "       0.96948933, 0.96948933, 0.93322749, 0.23246237, 0.19548684,\n",
       "       0.42834654, 0.36076743, 0.29860022, 0.47617875, 0.11660472,\n",
       "       0.51320177, 0.01600046, 0.24492273, 0.05468622, 0.54336529,\n",
       "       0.27907373, 0.08209792, 0.74681384, 0.52829265, 0.19140592,\n",
       "       0.19838631, 0.01713484, 0.25258407, 0.25258407, 0.72268985,\n",
       "       0.00477935, 0.00918075, 0.41495914, 0.72268985, 0.94200051,\n",
       "       0.94200051, 0.21555005, 0.03356557, 0.37249682, 0.03356557,\n",
       "       0.26735547, 0.22509665, 0.0963786 , 0.15938867, 0.21947228,\n",
       "       0.68704222, 0.68704222, 0.52120072, 0.90497004, 0.83656028,\n",
       "       0.59188724, 0.73514358, 0.24463838, 0.7977233 , 0.32096616,\n",
       "       0.63332705, 0.32096616, 0.21321298, 0.19914152, 0.00728622,\n",
       "       0.22756974, 0.26093625, 0.5337951 , 0.30422107, 0.3861141 ,\n",
       "       0.18548256, 0.3861141 , 0.78877942, 0.64088203, 0.47413396,\n",
       "       0.33415608, 0.44666019, 0.39009238, 0.41259712, 0.86295935,\n",
       "       0.41120126, 0.69081669, 0.44836515, 0.24527246, 0.24527246,\n",
       "       0.09430018, 0.92557934, 0.87155801, 0.06843417, 0.07838778,\n",
       "       0.52260444, 0.37284619, 0.45540892, 0.45540892, 0.24743493,\n",
       "       0.24743493, 0.62775433, 0.0659454 , 0.62775433, 0.74627673,\n",
       "       0.16964153, 0.38887007, 0.36753131, 0.3701196 , 0.36437707,\n",
       "       0.25686933, 0.41380814, 0.25140367, 0.41380814, 0.25140367,\n",
       "       0.41380814, 0.53693991, 0.91936334, 0.48721055, 0.64305831,\n",
       "       0.24978636, 0.30949373, 0.36271463, 0.50867379, 0.64305831,\n",
       "       0.36760301, 0.36760301, 0.28106423, 0.49393889, 0.15756799,\n",
       "       0.90797047, 0.5505815 , 0.66719218, 0.19874232, 0.76858316,\n",
       "       0.19874232, 0.60164822, 0.28571943, 0.72314706, 0.28571943,\n",
       "       0.26438681, 0.83886469, 0.26438681, 0.32418955, 0.2254826 ,\n",
       "       0.79825095, 0.571337  , 0.31660235, 0.50215373, 0.7902479 ,\n",
       "       0.50390046, 0.7902479 , 0.09564059, 0.44139691, 0.38623519,\n",
       "       0.60902698, 0.10974485, 0.02235923, 0.10205429, 0.1084413 ,\n",
       "       0.32270103, 0.60520676, 0.60520676, 0.29861252, 0.19233767,\n",
       "       0.98555446, 0.60520676, 0.61560862, 0.01072124, 0.28334432,\n",
       "       0.69363681, 0.09830777, 0.13805344, 0.00958588, 0.04618951,\n",
       "       0.34792572, 0.27862913, 0.21472419, 0.71433534, 0.27862913,\n",
       "       0.60384798, 0.5305342 , 0.26794085, 0.5305342 , 0.15887657,\n",
       "       0.68096399, 0.75094537, 0.73937548, 0.18670272, 0.48241067,\n",
       "       0.48241067, 0.09831807, 0.01397104, 0.83746284, 0.16389523,\n",
       "       0.17550673, 0.29024858, 0.01339425, 0.01339425, 0.63998484,\n",
       "       0.19785468, 0.40229385, 0.08253865, 0.07279741, 0.33493173,\n",
       "       0.50261522, 0.3276343 , 0.50474071, 0.77752251, 0.34129775,\n",
       "       0.49218211, 0.50474071, 0.35498825, 0.35498825, 0.27269892,\n",
       "       0.35498825, 0.65119958, 0.60597274, 0.25300934, 0.25300934,\n",
       "       0.29238656, 0.16732414, 0.27752286, 0.3810715 , 0.27752286,\n",
       "       0.65668318, 0.64968188, 0.2129364 , 0.05245296, 0.83800165,\n",
       "       0.32290394, 0.83800165, 0.16895523, 0.05329184, 0.4962666 ,\n",
       "       0.50954614, 0.11495777, 0.91341514, 0.63690013, 0.81119555,\n",
       "       0.30784904, 0.78233417, 0.44406405, 0.1764482 , 0.44406405,\n",
       "       0.26525577, 0.48616677, 0.48616677, 0.35947028, 0.35947028,\n",
       "       0.06328067, 0.68346644, 0.01078209, 0.80303414, 0.93162395,\n",
       "       0.61098794, 0.58900415, 0.47338359, 0.89600019, 0.08193321,\n",
       "       0.08193321, 0.00971441, 0.69219515, 0.77096501, 0.57139798,\n",
       "       0.37564097, 0.24002292, 0.25891282, 0.24002292, 0.45492993,\n",
       "       0.30159461, 0.79297925, 0.21689473, 0.36375091, 0.0704357 ,\n",
       "       0.62724172, 0.15238132, 0.29751899, 0.38218779, 0.19092643,\n",
       "       0.44547794, 0.44547794, 0.66606459, 0.77511046, 0.82645231,\n",
       "       0.77511046, 0.14457193, 0.14457193, 0.2571724 , 0.15987894,\n",
       "       0.59139043, 0.48983551, 0.47023379, 0.55341132, 0.09471857,\n",
       "       0.19325246, 0.21159811, 0.29746124, 0.29746124, 0.61110618,\n",
       "       0.29746124, 0.29729778, 0.52185202, 0.52185202, 0.42890077,\n",
       "       0.07307186, 0.07307186, 0.90292417, 0.07307186, 0.75900944,\n",
       "       0.72582768, 0.03297656, 0.08639129, 0.68119139, 0.15140257,\n",
       "       0.08639129, 0.12507991, 0.07432971, 0.0374517 , 0.03297656,\n",
       "       0.1699871 , 0.02710523, 0.70943894, 0.66102261, 0.54876401,\n",
       "       0.5472832 , 0.02710523, 0.57052539, 0.11614665, 0.63745124,\n",
       "       0.02646409, 0.42786705, 0.11614665, 0.57052539, 0.65122676,\n",
       "       0.39618766, 0.56357804, 0.17749385, 0.05678451, 0.67687291,\n",
       "       0.13153179, 0.29377816, 0.13153179, 0.81084773, 0.24772623,\n",
       "       0.44855608, 0.24772623, 0.44855608, 0.12346888, 0.62077598,\n",
       "       0.0073636 , 0.24400202, 0.16541915, 0.69626035, 0.18901519,\n",
       "       0.48889542, 0.52145037, 0.16541915, 0.46197548, 0.21411748,\n",
       "       0.35927752, 0.0546036 , 0.28853092, 0.92234938, 0.0546036 ,\n",
       "       0.28853092, 0.35927752, 0.76837642, 0.09213901, 0.49085436,\n",
       "       0.7119543 , 0.5022596 , 0.63064276, 0.5022596 , 0.7119543 ,\n",
       "       0.25406353, 0.25406353, 0.47514155, 0.98285995, 0.40006705,\n",
       "       0.33684854, 0.60983697, 0.76436819, 0.49202549, 0.48121962,\n",
       "       0.35443882, 0.35443882, 0.35443882, 0.48121962, 0.76496218,\n",
       "       0.38278812, 0.26255384, 0.95545178, 0.1218374 , 0.07017919,\n",
       "       0.60925889, 0.14198624, 0.36539882, 0.44159367, 0.26815498,\n",
       "       0.14198624, 0.11367996, 0.63902009, 0.1470122 , 0.35894747,\n",
       "       0.61013156, 0.41960091, 0.41960091, 0.67933804, 0.97423502,\n",
       "       0.48695286, 0.24236742, 0.24236742, 0.1648134 , 0.05604267,\n",
       "       0.38304397, 0.42753353, 0.05604267, 0.07656182, 0.66781662,\n",
       "       0.28371007, 0.55004816, 0.16182656, 0.55004816, 0.30185515,\n",
       "       0.60531561, 0.30185515, 0.31093165, 0.40864438, 0.73244039,\n",
       "       0.73244039, 0.95119275, 0.33122525])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_error = np.abs(preds_test - y_test)\n",
    "less_one = test_error[test_error < 1]\n",
    "less_point_one = test_error[test_error < 0.1]\n",
    "less_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.hist(less_one, bins=50);\n",
    "plt.hist(less_point_one, bins=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "k6VtWM8DT-8W"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-11-858d66e85edf>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-11-858d66e85edf>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    Calculate how many percent of the test set has an error less than 1/ 0.1\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# exercise: print the hsitogram of errors;\n",
    "Calculate how many percent of the test set has an error less than 1/ 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "36dNt0CjMWN9"
   },
   "source": [
    "**Conclusion:** The trained model could predict the wines' quality rating on a scale from 1 to 10 with an absolute error of around 0.5. Considering that most of the wines in the database have a rating between 3 and 8, this is not exactly a remarkable result. Perhaps the wine that's proclaimed to be high quality is the same as a cheaper variant, and calling either wine higher quality is just plain snobbism? Or perhaps a linear function based on the chemical compound is not enough to approximate the quality sticker given by professionals, and we require a more complex model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-JDt0MGaItgs"
   },
   "source": [
    "Linear regression is already implemented in multiple python libraries. One implementation from the sklearn package:\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_o-_D1coZneR"
   },
   "source": [
    "## Exercises\n",
    "\n",
    "**1.** Prove the following vectorized form we used in gradient descent:\n",
    "$$\\nabla_{\\theta} L(\\mathcal D, \\theta)=\\frac{1}{N}\\sum_{n=1}^N-2x_n(y_n-\\theta x_n)=-\\frac{2}{N}X^T(y-X\\theta)$$\n",
    "\n",
    "**2.** Using the trained network inspect its results:  \n",
    "- Print out how `theta` changes during training. Set the learning rate to a low and a high value and see what happens.\n",
    "- Train the linear regression. Plot the histogram of prediction errors.\n",
    "- Calculate the percentage of predictions where the error is less than 1 or less than 0.1\n",
    "\n",
    "\n",
    "**3.** Solve the linear regression problem with the normal equation (see above). Compare it to our gradient descent solution:  \n",
    "- Which one has the lower train/test error?\n",
    "- Which one has the lower loss (the $L(\\mathcal D,\\theta)$ value)?\n",
    "\n",
    "*(For those who did numerical analysis)* We are inverting the matrix $X^TX$, which can be numerically unstable. Calculate the condition number of $X^TX$. What does it mean for the stability of our normal equation? Recall that\n",
    "$$\\kappa(M)=\\frac{\\sigma_{max}(M)}{\\sigma_{min}(M)},$$\n",
    "where $\\sigma_{max}(M)$ and $\\sigma_{max}(M)$ are the maximal and minimal singular values of $M$.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Linear regression.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
